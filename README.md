# ğŸ§  Sign-Language-Detection-Model


---

## ğŸ“ Overview

This project is a **Real-Time Sign Language Detection System** that recognizes **English alphabet signs (Aâ€“Z)** using a webcam.  
It leverages **MediaPipe** for hand landmark detection and a **Machine Learning model** trained with **custom-collected gesture data**.

---

## ğŸš€ Features

âœ¨ **Real-time gesture recognition** using OpenCV  
âœ‹ **Hand landmark tracking** via MediaPipe Hands  
ğŸ§  **Custom-trained ML model** for Aâ€“Z alphabet detection  
âš¡ **Lightweight and efficient** â€” runs smoothly on most systems  
ğŸ’¾ Includes data collection, model training, and prediction scripts  

---

## ğŸ› ï¸ Tech Stack

| Category | Technologies |
|-----------|---------------|
| **Language** | Python |
| **Libraries** | OpenCV, MediaPipe, NumPy, Scikit-learn, Pickle |
| **Model** | Random Forest Regressor |
| **Environment** | Jupyter / VS Code / PyCharm |

---

## Project Structure

```bash
ğŸ“ Sign-Language-Detection-Model/
â”œâ”€â”€ collect_images.py      # Capture and save hand gesture data  
â”œâ”€â”€ create_dataset.py      # Organize and preprocess collected data  
â”œâ”€â”€ train_classifier.py    # Train the Random Forest Regressor model  
â”œâ”€â”€ test_model.p           # Run real-time sign recognition  
â””â”€â”€ requirements.txt       # Dependencies and versions  


---

## ğŸ§© How It Works

1. ğŸ–¼ï¸ **Data Collection** â€“ Capture gesture images for each alphabet using `collect_images.py`.  
2. ğŸ§® **Dataset Creation** â€“ Extract and save hand landmarks with `create_dataset.py`.  
3. ğŸ§  **Model Training** â€“ Train the Random Forest classifier using `train_classifier.py`.  
4. ğŸ” **Real-Time Detection** â€“ Use your webcam to detect and predict signs live.

---

## ğŸ¯ Future Enhancements

ğŸš€ Support for **dynamic gestures** (words or phrases) â€” with a larger dataset and GPU training  
ğŸ§¬ Integration with **CNN / Deep Learning** models for better accuracy  
ğŸ”Š Add **audio feedback** for recognized signs  
ğŸª„ Build a **user-friendly GUI** for interaction  


